## Computation
Computation is constraint, not magic. Machines transform inputs into outputs under strict rules. They excel at repetition, consistency, and traversing large state spaces that are well-defined. They falter when goals are ambiguous, when inputs embed social nuance, or when context shifts faster than models update.

Hardware and software expose hard limits: latency budgets, memory ceilings, and energy costs. Optimizing within these limits forces tradeoffs between fidelity and responsiveness. Treating computation as scarce keeps designs honest; treating it as free invites architectures that work only in slides.

The boundary between deterministic logic and probabilistic inference matters. Deterministic components offer guarantees and reproducibility. Probabilistic components offer flexibility but introduce variance and tail risk. Robust systems keep the deterministic skeleton visible so that when the probabilistic flesh misbehaves, we know where to intervene.
